{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acf5eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import requests\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99d6601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_env():\n",
    "    \n",
    "    env_path = os.path.join(os.getcwd(), '../.env')\n",
    "\n",
    "    if os.path.exists(env_path):\n",
    "        load_dotenv(dotenv_path=env_path)\n",
    "        \n",
    "        print(f\"Loaded environment variables from: \\033[94m{env_path}\\033[0m\")\n",
    "    else:\n",
    "            print(\"\\033[91mError: .env file not found. Please create one with your OPENAI_API_KEY.\\033[0m\")\n",
    "            sys.exit(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95e3c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8985caf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LangSmith 추적을 설정합니다. https://smith.langchain.com\n",
    "# !pip install -qU langchain-teddynote\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# 프로젝트 이름을 입력합니다.\n",
    "logging.langsmith(\"CH01-Basic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c2aa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# ChatOpenAI 모델을 인스턴스화합니다.\n",
    "model = ChatOpenAI()\n",
    "# 주어진 토픽에 대한 농담을 요청하는 프롬프트 템플릿을 생성합니다.\n",
    "prompt = PromptTemplate.from_template(\"{topic} 에 대하여 3문장으로 설명해줘.\")\n",
    "# 프롬프트와 모델을 연결하여 대화 체인을 생성합니다.\n",
    "chain = prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa43c748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 비동기 스트림을 사용하여 'YouTube' 토픽의 메시지를 처리합니다.\n",
    "async for token in chain.astream({\"topic\": \"YouTube\"}):\n",
    "    # 메시지 내용을 출력합니다. 줄바꿈 없이 바로 출력하고 버퍼를 비웁니다.\n",
    "    print(token, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
